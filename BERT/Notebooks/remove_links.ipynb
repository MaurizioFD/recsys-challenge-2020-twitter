{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load unique tweet tokens from file and remove links from tweets\n",
    "\n",
    "### Save in another file the number of links for that tweet and the links list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from TokenizerWrapper import special_tokens, TokenizerWrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS = 100\n",
    "HTTPS_TOKEN = '14120'\n",
    "LINK_STRING = \"https://t.co/\"\n",
    "LINK_TOKENS = '14120\\t131\\t120\\t120\\t188\\t119\\t11170\\t120'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_ID = \"tweet_features_tweet_id\"\n",
    "TWEET_TOKENS = \"tweet_features_text_tokens\"\n",
    "\n",
    "TWEET_TOKENS_FILE = \"tweet_tokens/text_tokens_no_hashtags_mentions.csv\"\n",
    "\n",
    "RESULT_PATH = \"tweet_tokens/text_tokens_clean.csv\"\n",
    "LINKS_PATH = \"tweet_tokens/links/links.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_remove_links(tokens):\n",
    "    \n",
    "    links_strings = []\n",
    "    encoded_links = []\n",
    "    \n",
    "    if HTTPS_TOKEN in tokens_list:\n",
    "        \n",
    "        decoded_tokens = tok.decode(tokens).split(' ')\n",
    "\n",
    "        mask = []\n",
    "\n",
    "        length = len(decoded_tokens)\n",
    "\n",
    "        finished  = False\n",
    "        index = 0\n",
    "        i = 0\n",
    "\n",
    "        while i < length and not finished:\n",
    "\n",
    "            dec_t = decoded_tokens[i]\n",
    "\n",
    "            if dec_t == 'https':\n",
    "                try:\n",
    "                    index = i + 7\n",
    "                    links_strings.append(decoded_tokens[index])\n",
    "                    for j in range(8):\n",
    "                        mask.append(False) # link splittato in 8 elementi tutti da rimuovere\n",
    "                    i += 8\n",
    "                    #print(initial_index, final_index)\n",
    "                except:\n",
    "                    #print(decoded_tokens)\n",
    "                    #print(i)\n",
    "                    #print(index)\n",
    "                    #print(decoded_tokens[i])\n",
    "                    for j in range(i, length):\n",
    "                        mask.append(False)\n",
    "                    finished = True\n",
    "            else:\n",
    "                mask.append(True)\n",
    "                i += 1\n",
    "\n",
    "        #print(decoded_tokens)\n",
    "        #print(len(decoded_tokens))\n",
    "        #print(mask)\n",
    "        #print(len(mask))\n",
    "\n",
    "        tokens_arr = np.array(decoded_tokens)\n",
    "        tokens_arr = tokens_arr[mask]\n",
    "        decoded_tokens = tokens_arr.tolist()\n",
    "        tokens = tok.encode(' '.join(decoded_tokens))\n",
    "        tokens = tokens[1:-1]  # ignore CLS ans SEP (they are duplicated)\n",
    "    \n",
    "        #print(tok.decode(tokens))\n",
    "        # encode only the last string in each link (ignore the \"https://t.co\")\n",
    "        for l in range(len(links_strings)):\n",
    "            if links_strings[l] == '[SEP]':\n",
    "                links_strings.pop(l)\n",
    "            else:\n",
    "                links_strings[l] = links_strings[l].replace(',', '').replace('.','')  # a link cointained ',' (in un csv spostava tutte le colonne)\n",
    "                enc_l = tok.encode(links_strings[l]) \n",
    "                encoded_links.append(enc_l[1:-1])  # ignore CLS ans SEP\n",
    "        \n",
    "        #print(links_strings)\n",
    "    \n",
    "    else:\n",
    "        tokens[-1] = '102'  # remove the last \"\\n\" (tokens ends with \"102\\n\")\n",
    "            \n",
    "    return tokens, encoded_links, links_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "links_dict = {}\n",
    "current_mapping = 0\n",
    "\n",
    "def map_links(m_list):\n",
    "    global links_dict, current_mapping\n",
    "    mapped = []\n",
    "    for m in m_list:\n",
    "        if m not in links_dict:\n",
    "            links_dict[m] = current_mapping\n",
    "            current_mapping += 1\n",
    "        \n",
    "        mapped.append(links_dict[m])\n",
    "    \n",
    "    return mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweet(index, text_tokens):\n",
    "    string = index + ',' + '\\t'.join(map(str, text_tokens)) + '\\n'\n",
    "    result_file.write(string)\n",
    "    \n",
    "\n",
    "def save_links(text_tokens, text, mapped, count):\n",
    "    for i in range(len(text_tokens)):\n",
    "        text_tokens[i] = '\\t'.join(map(str, text_tokens[i]))\n",
    "    \n",
    "    # each mentions is separated by a \";\"\n",
    "    # each token in a mention is 2008', '56210'separated by a \"\\t\"\n",
    "    string = str(count) + ',' + ';'.join(text_tokens) + ',' + '\\t'.join(text) + ',' + '\\t'.join(map(str, mapped)) + '\\n'\n",
    "    \n",
    "    links_file.write(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_line(l):\n",
    "    l = l.split(',')\n",
    "    t_id = l[0]\n",
    "    t_list = l[1].split('\\t')  # replace(\"\\\\n\",'').replace(\"\\\\t\",'\\t')\n",
    "    \n",
    "    return t_id, t_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_to_int = lambda x: int(x)\n",
    "f_int = lambda x: list(map(f_to_int, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok = TokenizerWrapper()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the header (columns names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = open(RESULT_PATH, \"w+\")\n",
    "links_file = open(LINKS_PATH, \"w+\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_file.write(TWEET_ID + ',' + TWEET_TOKENS + \"\\n\")\n",
    "links_file.write(\"links_count,links_tokens,links_text,links_mapping\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open files to be read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_file = open(TWEET_TOKENS_FILE, \"r\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row:  0  - Elapsed time:  4.5299530029296875e-06\n",
      "Row:  1000000  - Elapsed time:  424.5548131465912\n",
      "Row:  2000000  - Elapsed time:  828.619425535202\n",
      "Row:  3000000  - Elapsed time:  1208.9953210353851\n",
      "Row:  4000000  - Elapsed time:  1584.635621547699\n",
      "Row:  5000000  - Elapsed time:  1952.890278339386\n",
      "Row:  6000000  - Elapsed time:  2317.298236846924\n",
      "Row:  7000000  - Elapsed time:  2678.524081468582\n",
      "Row:  8000000  - Elapsed time:  3033.8501262664795\n",
      "Row:  9000000  - Elapsed time:  3384.5517551898956\n",
      "Row:  10000000  - Elapsed time:  3734.719610929489\n",
      "Row:  11000000  - Elapsed time:  4095.2562601566315\n",
      "Row:  12000000  - Elapsed time:  4454.956626176834\n",
      "Row:  13000000  - Elapsed time:  4808.66837477684\n",
      "Row:  14000000  - Elapsed time:  5163.450683116913\n",
      "Row:  15000000  - Elapsed time:  5511.863975524902\n",
      "Row:  16000000  - Elapsed time:  5854.46142077446\n",
      "Row:  17000000  - Elapsed time:  6193.926142454147\n",
      "Row:  18000000  - Elapsed time:  6529.786390781403\n",
      "Row:  19000000  - Elapsed time:  6865.178060770035\n",
      "Row:  20000000  - Elapsed time:  7200.877314329147\n",
      "Row:  21000000  - Elapsed time:  7533.501046657562\n",
      "Row:  22000000  - Elapsed time:  7866.281197309494\n",
      "Row:  23000000  - Elapsed time:  8198.565121412277\n",
      "Row:  24000000  - Elapsed time:  8524.904338121414\n",
      "Row:  25000000  - Elapsed time:  8853.714297056198\n",
      "Row:  26000000  - Elapsed time:  9182.119093179703\n",
      "Row:  27000000  - Elapsed time:  9509.008103132248\n",
      "Row:  28000000  - Elapsed time:  9838.368710756302\n",
      "Row:  29000000  - Elapsed time:  10164.759948015213\n",
      "Row:  30000000  - Elapsed time:  10489.064599514008\n",
      "Row:  31000000  - Elapsed time:  10811.715426921844\n",
      "Row:  32000000  - Elapsed time:  11144.718051671982\n",
      "Row:  33000000  - Elapsed time:  11471.352336883545\n",
      "Row:  34000000  - Elapsed time:  11788.72124671936\n",
      "Row:  35000000  - Elapsed time:  12103.71551656723\n",
      "Row:  36000000  - Elapsed time:  12419.372928619385\n",
      "Row:  37000000  - Elapsed time:  12734.682692527771\n",
      "Row:  38000000  - Elapsed time:  13051.263395547867\n",
      "Row:  39000000  - Elapsed time:  13366.398380994797\n",
      "Row:  40000000  - Elapsed time:  13679.014024019241\n",
      "Row:  41000000  - Elapsed time:  13992.581126451492\n",
      "Row:  42000000  - Elapsed time:  14301.784694194794\n",
      "Row:  43000000  - Elapsed time:  14612.175117492676\n",
      "Row:  44000000  - Elapsed time:  14922.154070854187\n",
      "Row:  45000000  - Elapsed time:  15232.729558229446\n",
      "Row:  46000000  - Elapsed time:  15549.766259908676\n",
      "Row:  47000000  - Elapsed time:  15870.2306599617\n",
      "Row:  48000000  - Elapsed time:  16177.96025276184\n",
      "Row:  49000000  - Elapsed time:  16493.86926627159\n",
      "Row:  50000000  - Elapsed time:  16812.806696414948\n",
      "Row:  51000000  - Elapsed time:  17122.776395082474\n",
      "Row:  52000000  - Elapsed time:  17430.41730904579\n",
      "Row:  53000000  - Elapsed time:  17738.924638032913\n",
      "Row:  54000000  - Elapsed time:  18046.03318953514\n",
      "Row:  55000000  - Elapsed time:  18360.921984672546\n",
      "Row:  56000000  - Elapsed time:  18679.9847509861\n",
      "Row:  57000000  - Elapsed time:  18994.772294282913\n",
      "Row:  58000000  - Elapsed time:  19299.188104391098\n",
      "Row:  59000000  - Elapsed time:  19599.93284344673\n",
      "Row:  60000000  - Elapsed time:  19902.052325725555\n",
      "Row:  61000000  - Elapsed time:  20205.30102443695\n",
      "Row:  62000000  - Elapsed time:  20504.084300756454\n",
      "Row:  63000000  - Elapsed time:  20805.590428590775\n",
      "Row:  64000000  - Elapsed time:  21120.83528995514\n",
      "Row:  65000000  - Elapsed time:  21432.233370780945\n",
      "Row:  66000000  - Elapsed time:  21741.11511874199\n",
      "Row:  67000000  - Elapsed time:  22051.41672873497\n",
      "Row:  68000000  - Elapsed time:  22362.330420732498\n",
      "Row:  69000000  - Elapsed time:  22667.447901010513\n",
      "Row:  70000000  - Elapsed time:  22970.125841379166\n",
      "Row:  71000000  - Elapsed time:  23267.35054063797\n",
      "Row:  72000000  - Elapsed time:  23563.540110588074\n",
      "Row:  73000000  - Elapsed time:  23862.286571979523\n",
      "CPU times: user 6h 38min 21s, sys: 2min 11s, total: 6h 40min 32s\n",
      "Wall time: 6h 40min 22s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ~3h EXECUTION\n",
    "\n",
    "# ignore header\n",
    "line = tokens_file.readline()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "finished = False\n",
    "row = 0\n",
    "\n",
    "while not finished:  # and row < 10000:\n",
    "    \n",
    "    links_tokens = []\n",
    "    links_strings = []\n",
    "    mapped_links = []\n",
    "    links_count = 0\n",
    "    \n",
    "    if row % 1000000 == 0:\n",
    "        elapsed_time = time.time() - start\n",
    "        print('Row: ', row, ' - Elapsed time: ', elapsed_time)\n",
    "            \n",
    "    line = str(tokens_file.readline())\n",
    "    \n",
    "    #print(line)\n",
    "    \n",
    "    if line != '':\n",
    "        \n",
    "        tweet_id, tokens_list = split_line(line)\n",
    "\n",
    "        #print('\\ntweet_id: ', tweet_id)\n",
    "        #print(tokens_list)\n",
    "        #decoded_tweet = tok.decode(tokens_list)\n",
    "        #print('\\n', decoded_tweet, '\\n')\n",
    "\n",
    "        tokens_list, links_tokens, links_strings = get_remove_links(tokens_list)\n",
    "\n",
    "        links_count = len(links_tokens)\n",
    "        mapped_links = map_links(links_strings)\n",
    "\n",
    "        #print('text tokens: ', tokens_list)\n",
    "        #print('links: ', links_tokens)\n",
    "        #print('links text: ', links_strings)\n",
    "        #print('mapped links: ', mapped_links)\n",
    "        #print('links count: ', links_count)\n",
    "\n",
    "        save_tweet(tweet_id, tokens_list)\n",
    "        save_links(links_tokens, links_strings, mapped_links, links_count)\n",
    "\n",
    "    else:\n",
    "        finished = True\n",
    "            \n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_file.close()\n",
    "\n",
    "result_file.close()\n",
    "links_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save mapping to json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_links_mapping = json.dumps(links_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tweet_tokens/links/links_mapping.json', 'w+') as f:\n",
    "    f.write(json_links_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18991547"
      ]
     },
     "execution_count": 403,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(links_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.26 ms, sys: 21 µs, total: 8.28 ms\n",
      "Wall time: 6.26 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(RESULT_PATH,\n",
    "                    #names=[TWEET_ID],\n",
    "                    nrows=N_ROWS,\n",
    "                    header=0,\n",
    "                    index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_features_text_tokens</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tweet_features_tweet_id</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101\\t6417\\t3410\\t3398\\t3184\\t1909\\t56910\\t1683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101\\t102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101\\t62342\\t10858\\t54439\\t19571\\t22480\\t7831\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101\\t58955\\t10898\\t103305\\t1901\\t16181\\t7168\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101\\t2435\\t5656\\t2594\\t8279\\t8623\\t1925\\t64126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>101\\t187\\t14394\\t12011\\t102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>101\\t115\\t18296\\t33989\\t54006\\t10230\\t14168\\t2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>101\\t123\\t118\\t10348\\t118\\t10197\\t102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>101\\t11065\\t16138\\t10114\\t12888\\t10271\\t106\\t102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>101\\t10149\\t11178\\t10108\\t189\\t13246\\t13486\\t1...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                tweet_features_text_tokens\n",
       "tweet_features_tweet_id                                                   \n",
       "0                        101\\t6417\\t3410\\t3398\\t3184\\t1909\\t56910\\t1683...\n",
       "1                                                                 101\\t102\n",
       "2                        101\\t62342\\t10858\\t54439\\t19571\\t22480\\t7831\\t...\n",
       "3                        101\\t58955\\t10898\\t103305\\t1901\\t16181\\t7168\\t...\n",
       "4                        101\\t2435\\t5656\\t2594\\t8279\\t8623\\t1925\\t64126...\n",
       "...                                                                    ...\n",
       "95                                             101\\t187\\t14394\\t12011\\t102\n",
       "96                       101\\t115\\t18296\\t33989\\t54006\\t10230\\t14168\\t2...\n",
       "97                                   101\\t123\\t118\\t10348\\t118\\t10197\\t102\n",
       "98                        101\\t11065\\t16138\\t10114\\t12888\\t10271\\t106\\t102\n",
       "99                       101\\t10149\\t11178\\t10108\\t189\\t13246\\t13486\\t1...\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 383,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 11.4 ms, sys: 0 ns, total: 11.4 ms\n",
      "Wall time: 9.56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(LINKS_PATH,\n",
    "                    #names=[TWEET_ID],\n",
    "                    nrows=N_ROWS,\n",
    "                    header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>links_tokens</th>\n",
       "      <th>links_text</th>\n",
       "      <th>links_mapping</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>links_count</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>178\\t71492\\t11274\\t10112\\t10759\\t11274\\t11166\\...</td>\n",
       "      <td>jbcBe1B5lP</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>177\\t11779\\t10418\\t10457\\t11274\\t10874\\t11733\\...</td>\n",
       "      <td>iVjbBwKXHc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141\\t10305\\t25743\\t13034\\t10729\\t11527\\t10410\\...</td>\n",
       "      <td>DzfsW2ttpL</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>172\\t10738\\t15417\\t11779\\t11011\\t11537\\t11166\\...</td>\n",
       "      <td>dAJV4N5H2A</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  links_tokens  links_text  \\\n",
       "links_count                                                                  \n",
       "0                                                          NaN         NaN   \n",
       "1            178\\t71492\\t11274\\t10112\\t10759\\t11274\\t11166\\...  jbcBe1B5lP   \n",
       "1            177\\t11779\\t10418\\t10457\\t11274\\t10874\\t11733\\...  iVjbBwKXHc   \n",
       "1            141\\t10305\\t25743\\t13034\\t10729\\t11527\\t10410\\...  DzfsW2ttpL   \n",
       "0                                                          NaN         NaN   \n",
       "...                                                        ...         ...   \n",
       "1            172\\t10738\\t15417\\t11779\\t11011\\t11537\\t11166\\...  dAJV4N5H2A   \n",
       "0                                                          NaN         NaN   \n",
       "0                                                          NaN         NaN   \n",
       "0                                                          NaN         NaN   \n",
       "0                                                          NaN         NaN   \n",
       "\n",
       "            links_mapping  \n",
       "links_count                \n",
       "0                     NaN  \n",
       "1                       0  \n",
       "1                       1  \n",
       "1                       2  \n",
       "0                     NaN  \n",
       "...                   ...  \n",
       "1                      59  \n",
       "0                     NaN  \n",
       "0                     NaN  \n",
       "0                     NaN  \n",
       "0                     NaN  \n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
