{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load unique tweet tokens from file and remove escaped chars "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ROWS = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special Chars (represented by BERT's tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_string = \"111\\t175\\t10123\\t132\" # \"& gt ;\"\n",
    "lt_string = \"111\\t43900\\t132\" # \"& lt ;\"\n",
    "amp_string = \"111\\t10392\\t10410\\t132\" # \"& amp ;\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "TWEET_ID = \"tweet_features_tweet_id\"\n",
    "TWEET_TOKENS = \"tweet_features_text_tokens\"\n",
    "\n",
    "TWEET_TOKENS_FILE = \"tweet_tokens/text_tokens_unique_all.csv\"\n",
    "\n",
    "RESULT_PATH = \"tweet_tokens/text_tokens_no_escaped_chars.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = open(RESULT_PATH, \"w+\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the header (columns names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_file.write(TWEET_ID + ',' + TWEET_TOKENS + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Open files to be read and perform the substitution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_file = open(TWEET_TOKENS_FILE, \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_tweet(index, text):\n",
    "    line = index + ','\n",
    "    for item in text:\n",
    "        line += item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14.8 ms, sys: 12.6 ms, total: 27.5 ms\n",
      "Wall time: 26.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# ABOUT ~8 MINUTES EXECUTION ON THE WHOLE DATASET\n",
    "\n",
    "# ignore header\n",
    "tokens_file.readline()\n",
    "\n",
    "finished = False\n",
    "i = 0\n",
    "\n",
    "while not finished and i < N_ROWS:\n",
    "    \n",
    "    line = str(tokens_file.readline())\n",
    "    \n",
    "    if line != '':\n",
    "        \n",
    "        line = line.replace(\"\\\\n\",'').replace(\"\\\\t\",'\\t')\n",
    "        \n",
    "        if gt_string in line:\n",
    "            line = line.replace(gt_string, gt_token)\n",
    "        if lt_string in line:\n",
    "            line = line.replace(lt_string, lt_token)\n",
    "        if amp_string in line:\n",
    "            line = line.replace(amp_string, amp_token)\n",
    "            \n",
    "        #print(line)\n",
    "        \n",
    "        result_file.write(line)\n",
    "        \n",
    "    else:\n",
    "        finished = True\n",
    "\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_file.close()\n",
    "\n",
    "result_file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 139 ms, sys: 19.7 ms, total: 158 ms\n",
      "Wall time: 157 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "df = pd.read_csv(RESULT_PATH,\n",
    "                    names=[TWEET_ID],\n",
    "                    #nrows=N_ROWS,\n",
    "                    header=0,\n",
    "                    index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_features_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101\\t6417\\t3410\\t3398\\t3184\\t1909\\t56910\\t1683...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101\\t14120\\t131\\t120\\t120\\t188\\t119\\t11170\\t12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101\\t62342\\t10858\\t54439\\t19571\\t22480\\t7831\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101\\t58955\\t10898\\t103305\\t1901\\t16181\\t7168\\t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101\\t2435\\t5656\\t2594\\t8279\\t8623\\t1925\\t64126...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>101\\t50013\\t140\\t20764\\t12989\\t72493\\t15834\\t2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>101\\t14120\\t131\\t120\\t120\\t188\\t119\\t11170\\t12...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>101\\t56898\\t137\\t170\\t10806\\t168\\t22185\\t40762...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>101\\t11862\\t13321\\t24054\\t112\\t187\\t102498\\t19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>101\\t3197\\t2179\\t1946\\t8618\\t2594\\t1881\\t1995\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tweet_features_tweet_id\n",
       "0      101\\t6417\\t3410\\t3398\\t3184\\t1909\\t56910\\t1683...\n",
       "1      101\\t14120\\t131\\t120\\t120\\t188\\t119\\t11170\\t12...\n",
       "2      101\\t62342\\t10858\\t54439\\t19571\\t22480\\t7831\\t...\n",
       "3      101\\t58955\\t10898\\t103305\\t1901\\t16181\\t7168\\t...\n",
       "4      101\\t2435\\t5656\\t2594\\t8279\\t8623\\t1925\\t64126...\n",
       "...                                                  ...\n",
       "49995  101\\t50013\\t140\\t20764\\t12989\\t72493\\t15834\\t2...\n",
       "49996  101\\t14120\\t131\\t120\\t120\\t188\\t119\\t11170\\t12...\n",
       "49997  101\\t56898\\t137\\t170\\t10806\\t168\\t22185\\t40762...\n",
       "49998  101\\t11862\\t13321\\t24054\\t112\\t187\\t102498\\t19...\n",
       "49999  101\\t3197\\t2179\\t1946\\t8618\\t2594\\t1881\\t1995\\...\n",
       "\n",
       "[50000 rows x 1 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 470,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TWEET_ID_FILE,\n",
    "                    names=[TWEET_ID],\n",
    "                    compression='gzip',\n",
    "                    #nrows=N_ROWS,\n",
    "                    header=0,\n",
    "                    index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "904761"
      ]
     },
     "execution_count": 471,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[TWEET_ID].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Older code for padding using pandas (should be no more useful)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_chunk(chunk, path):\n",
    "    chunk.to_csv(path, \n",
    "                 columns=[COLUMN_NAME],\n",
    "                 header=None,\n",
    "                 mode='a',\n",
    "                 compression='gzip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "for chunk in pd.read_csv(PATH,\n",
    "                            chunksize=CHUNKSIZE,\n",
    "                            names=[TWEET_ID],\n",
    "                            compression='gzip',\n",
    "                            nrows=N_ROWS,\n",
    "                            header=0,\n",
    "                            index_col=0):\n",
    "    \n",
    "    for row in chunk[TWEET_TOKENS]:\n",
    "\n",
    "        for i in range(len(row), max_tweet_length):\n",
    "            row.append(PAD)\n",
    "\n",
    "        if (len(row) != max_tweet_length):\n",
    "            print('Error')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(PATH_TWEETS_PADDED,\n",
    "                 header=None,\n",
    "                 mode='w',\n",
    "                 compression='gzip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
